# Configuración del modelo LLM
GOOGLE_API_KEY=AIzaSyC5sj3OD9o845qA_9s34ESLyk4T6m5ssQs
LLM_MODEL=gemini-1.5-pro
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=8192

# Configuración de embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Configuración de memoria
DEFAULT_MEMORY_TYPE=buffer
MEMORY_MAX_TOKEN_LIMIT=2000

# Configuración de vectorización
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Configuración de logging
LOG_LEVEL=INFO
LOG_FILE_ENABLED=True